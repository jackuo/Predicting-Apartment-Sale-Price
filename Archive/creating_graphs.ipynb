{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from collections import defaultdict\n",
    "\n",
    "import re\n",
    "from datetime import datetime\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "# Necessary imports\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge #ordinary linear regression + w/ ridge regularization\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(file_location):\n",
    "    with open(file_location, \"rb\") as picklefile:\n",
    "        df = pickle.load(picklefile)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_pickle(\"all_midtown_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Season Added\n",
      "3. Days on Market Added\n",
      "4. Filled Beds to indicate Studio\n",
      "5. Apt Nulls Filled\n",
      "6. Renamed Columns\n"
     ]
    }
   ],
   "source": [
    "# Remove Building Type column. They are all Condos\n",
    "df = df.drop(\"Building Type\", axis=1)\n",
    "\n",
    "# Sort values by date sold\n",
    "df = df.sort_values(by = 'sold_date_dt', ascending = False)\n",
    "\n",
    "# Drop duplicate rows\n",
    "#df_no_dup = df.drop_duplicates(subset = 'full_name', keep = 'first').reset_index(drop = True)\n",
    "#print(\"1. Duplicates Removed\")\n",
    "\n",
    "# Add season\n",
    "df['sold_season'] = (df['sold_date_dt']\n",
    "                     .dt\n",
    "                     .month\n",
    "                     .map({1 : 'Winter', \n",
    "                           2 : 'Winter',\n",
    "                           3 : 'Spring',\n",
    "                           4 : 'Spring',\n",
    "                           5 : 'Spring',\n",
    "                           6 : 'Summer',\n",
    "                           7 : 'Summer',\n",
    "                           8 : 'Summer',\n",
    "                           9 : 'Fall',\n",
    "                           10 : 'Fall',\n",
    "                           11 : 'Fall',\n",
    "                           12 : 'Winter'}))\n",
    "print(\"2. Season Added\")\n",
    "\n",
    "# Add days on market column, and convert datetime timedelta to float\n",
    "df['days_on_market_1'] = df['sold_date_dt'] - df['Listed']\n",
    "df['days_on_market_1'] = (df['days_on_market_1']/np.timedelta64(1, 'D'))\n",
    "print(\"3. Days on Market Added\")\n",
    "\n",
    "# Fill to indicate Studio\n",
    "df['beds'] = df['beds'].fillna(0)\n",
    "print(\"4. Filled Beds to indicate Studio\")\n",
    "\n",
    "### Fixing rows where there is no condo ###\n",
    "# Find where apt = NaN\n",
    "df_apt_na = df[df['apt_floor'].isna()]\n",
    "\n",
    "# Fill Apt nulls, move bldg address to correct place, and delete bldg name\n",
    "for index, row in df_apt_na.iterrows():\n",
    "    #print(row['apt_floor'])\n",
    "    #print(np.isnan(row['apt_floor']))\n",
    "    try:\n",
    "        if np.isnan(row['apt_floor']):\n",
    "            df.loc[index, 'apt_floor'] = int(re.findall('\\d+', row['bldg_addr'])[0]) # assign value in full dataframe\n",
    "            df.loc[index, 'bldg_addr'] = df.loc[index]['bldg_name'] # move building address over to correct column\n",
    "            df.loc[index, 'bldg_name'] = np.nan # clears building name\n",
    "            #print(index)\n",
    "        else:\n",
    "            continue\n",
    "    except:\n",
    "        continue\n",
    "print(\"5. Apt Nulls Filled\")\n",
    "\n",
    "# Rename Columns\n",
    "df = df.rename(columns = {\"Listed\": \"listed\", \n",
    "                 \"Days on Market\": \"days_on_market\", \n",
    "                 \"Neighborhood\": \"neighborhood\", \n",
    "                 \"Monthly Common Charges\": \"monthly_common_charges\", \n",
    "                 \"Monthly Real Estate Taxes\": \"monthly_real_estate_taxes\", \n",
    "                 \"Minimum Down Payment\": \"minimum_down_payment\", \n",
    "                 \"Doorman\": \"doorman\", \n",
    "                 \"Last Price Change\": \"last_price_change\"})\n",
    "print(\"6. Renamed Columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_clean['year'] = df_clean['sold_date_dt'].apply(lambda x: x.strftime('%Y'))\n",
    "df['year'] = df['sold_date_dt'].apply(lambda x: x.strftime('%Y'))\n",
    "\n",
    "# Want only 2 bedrooms or less\n",
    "df = df[df['beds'] < 2.5]\n",
    "\n",
    "# Convert days on market to int\n",
    "df['days_on_market'] = pd.to_numeric(df['days_on_market'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22937, 25)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 22945 values initially\n",
    "# 15008 values once duplicates are dropped\n",
    "df_drop = df.drop_duplicates(subset=['full_name', 'sold_date']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apt_floor</th>\n",
       "      <th>bldg_rating</th>\n",
       "      <th>sold_price</th>\n",
       "      <th>price_per_sqft</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>days_on_market</th>\n",
       "      <th>monthly_common_charges</th>\n",
       "      <th>monthly_real_estate_taxes</th>\n",
       "      <th>minimum_down_payment</th>\n",
       "      <th>days_on_market_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>14978.000000</td>\n",
       "      <td>14392.000000</td>\n",
       "      <td>1.500300e+04</td>\n",
       "      <td>6445.000000</td>\n",
       "      <td>6445.000000</td>\n",
       "      <td>15003.000000</td>\n",
       "      <td>14975.000000</td>\n",
       "      <td>7083.000000</td>\n",
       "      <td>7.006000e+03</td>\n",
       "      <td>6707.000000</td>\n",
       "      <td>2856.000000</td>\n",
       "      <td>7083.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>159.778408</td>\n",
       "      <td>75.730753</td>\n",
       "      <td>1.315659e+06</td>\n",
       "      <td>1447.735764</td>\n",
       "      <td>951.232894</td>\n",
       "      <td>1.174498</td>\n",
       "      <td>1.459065</td>\n",
       "      <td>1789.009600</td>\n",
       "      <td>1.306234e+03</td>\n",
       "      <td>937.680781</td>\n",
       "      <td>0.109436</td>\n",
       "      <td>47.166173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>630.924406</td>\n",
       "      <td>11.085550</td>\n",
       "      <td>1.224740e+06</td>\n",
       "      <td>550.755976</td>\n",
       "      <td>384.575335</td>\n",
       "      <td>0.688777</td>\n",
       "      <td>0.565285</td>\n",
       "      <td>1052.018098</td>\n",
       "      <td>1.707124e+04</td>\n",
       "      <td>1114.621562</td>\n",
       "      <td>0.055149</td>\n",
       "      <td>835.310532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>1.000000e+05</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.060000e+02</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-6004.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>6.890000e+05</td>\n",
       "      <td>1099.000000</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>895.500000</td>\n",
       "      <td>6.490000e+02</td>\n",
       "      <td>523.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>9.850000e+05</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>878.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1689.000000</td>\n",
       "      <td>8.850000e+02</td>\n",
       "      <td>773.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>126.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>1.540000e+06</td>\n",
       "      <td>1650.000000</td>\n",
       "      <td>1176.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2562.000000</td>\n",
       "      <td>1.301750e+03</td>\n",
       "      <td>1152.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>237.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>6504.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>2.200000e+07</td>\n",
       "      <td>6705.000000</td>\n",
       "      <td>3895.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4517.000000</td>\n",
       "      <td>1.426830e+06</td>\n",
       "      <td>75980.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>3706.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          apt_floor   bldg_rating    sold_price  price_per_sqft  square_feet  \\\n",
       "count  14978.000000  14392.000000  1.500300e+04     6445.000000  6445.000000   \n",
       "mean     159.778408     75.730753  1.315659e+06     1447.735764   951.232894   \n",
       "std      630.924406     11.085550  1.224740e+06      550.755976   384.575335   \n",
       "min        1.000000     44.000000  1.000000e+05      190.000000   285.000000   \n",
       "25%        7.000000     68.000000  6.890000e+05     1099.000000   668.000000   \n",
       "50%       16.000000     78.000000  9.850000e+05     1338.000000   878.000000   \n",
       "75%       32.000000     84.000000  1.540000e+06     1650.000000  1176.000000   \n",
       "max     6504.000000     99.000000  2.200000e+07     6705.000000  3895.000000   \n",
       "\n",
       "               beds         baths  days_on_market  monthly_common_charges  \\\n",
       "count  15003.000000  14975.000000     7083.000000            7.006000e+03   \n",
       "mean       1.174498      1.459065     1789.009600            1.306234e+03   \n",
       "std        0.688777      0.565285     1052.018098            1.707124e+04   \n",
       "min        0.000000      1.000000        2.000000            2.060000e+02   \n",
       "25%        1.000000      1.000000      895.500000            6.490000e+02   \n",
       "50%        1.000000      1.000000     1689.000000            8.850000e+02   \n",
       "75%        2.000000      2.000000     2562.000000            1.301750e+03   \n",
       "max        2.000000      5.000000     4517.000000            1.426830e+06   \n",
       "\n",
       "       monthly_real_estate_taxes  minimum_down_payment  days_on_market_1  \n",
       "count                6707.000000           2856.000000       7083.000000  \n",
       "mean                  937.680781              0.109436         47.166173  \n",
       "std                  1114.621562              0.055149        835.310532  \n",
       "min                   101.000000              0.100000      -6004.000000  \n",
       "25%                   523.000000              0.100000         48.000000  \n",
       "50%                   773.000000              0.100000        126.000000  \n",
       "75%                  1152.000000              0.100000        237.000000  \n",
       "max                 75980.000000              0.900000       3706.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drop.describe()\n",
    "# Want apartments with only 0, 1, 2 bedrooms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geolocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"specify_your_app_name_here\", timeout = 3)\n",
    "location = geolocator.geocode(df_drop['bldg_addr'][0] + \" NYC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['sold_price']\n",
    "bldg = ['full_name', 'bldg_name', 'bldg_addr'] #'bldg_name', 'bldg_addr']\n",
    "cont = ['bldg_rating', \n",
    "        'apt_floor',\n",
    "        'square_feet', \n",
    "        'beds', \n",
    "        'baths', \n",
    "        'monthly_common_charges', \n",
    "        'monthly_real_estate_taxes']\n",
    "cat = ['sold_season', 'neighborhood', 'year']\n",
    "model_columns = bldg + cont + cat + target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graph = df_drop[model_columns].dropna().reset_index(drop = True)\n",
    "df_graph = df_graph[df_graph['sold_price'] < 8000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'145 East 48th Street'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_graph['bldg_addr'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.75515\n",
      "-73.9723602987829\n"
     ]
    }
   ],
   "source": [
    "test = geolocator.geocode(df_graph['bldg_addr'][0] + ' NYC')\n",
    "print(test.latitude)\n",
    "print(test.longitude)\n",
    "#test.raw['address']['postcode']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location(Cosmopolitan, 145, East 48th Street, Turtle Bay, Manhattan Community Board 5, Manhattan, New York County, NYC, New York, 10017, USA, (40.75515, -73.9723602987829, 0.0))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"specify_your_app_name_here\")\n",
    "\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)\n",
    "#df['location'] = df['name'].apply(geocode)\n",
    "\n",
    "#df['point'] = df['location'].apply(lambda loc: tuple(loc.point) if loc else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*(0           145 East 48th Street NYC\n",
      "1           350 West 42nd Street NYC\n",
      "2             211 Madison Avenue NYC\n",
      "3           350 West 57th Street NYC\n",
      "4           500 West 43rd Street NYC\n",
      "                    ...             \n",
      "4387        150 West 51st Street NYC\n",
      "4388        224 East 52nd Street NYC\n",
      "4389        240 East 47th Street NYC\n",
      "4390    845 United Nations Plaza NYC\n",
      "4391    845 United Nations Plaza NYC\n",
      "Name: bldg_addr, Length: 4375, dtype: object,), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/geopy/geocoders/base.py\", line 355, in _call_geocoder\n",
      "    page = requester(req, timeout=timeout, **kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/urllib/request.py\", line 532, in open\n",
      "    response = meth(req, response)\n",
      "  File \"/anaconda3/lib/python3.6/urllib/request.py\", line 642, in http_response\n",
      "    'http', request, response, code, msg, hdrs)\n",
      "  File \"/anaconda3/lib/python3.6/urllib/request.py\", line 570, in error\n",
      "    return self._call_chain(*args)\n",
      "  File \"/anaconda3/lib/python3.6/urllib/request.py\", line 504, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/anaconda3/lib/python3.6/urllib/request.py\", line 650, in http_error_default\n",
      "    raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "urllib.error.HTTPError: HTTP Error 429: Too Many Requests\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/geopy/extra/rate_limiter.py\", line 126, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/geopy/geocoders/osm.py\", line 387, in geocode\n",
      "    self._call_geocoder(url, timeout=timeout), exactly_one\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/geopy/geocoders/base.py\", line 373, in _call_geocoder\n",
      "    raise ERROR_CODE_MAP[code](message)\n",
      "geopy.exc.GeocoderQuotaExceeded: HTTP Error 429: Too Many Requests\n",
      "RateLimiter caught an error, retrying (1/2 tries). Called with (*(0           145 East 48th Street NYC\n",
      "1           350 West 42nd Street NYC\n",
      "2             211 Madison Avenue NYC\n",
      "3           350 West 57th Street NYC\n",
      "4           500 West 43rd Street NYC\n",
      "                    ...             \n",
      "4387        150 West 51st Street NYC\n",
      "4388        224 East 52nd Street NYC\n",
      "4389        240 East 47th Street NYC\n",
      "4390    845 United Nations Plaza NYC\n",
      "4391    845 United Nations Plaza NYC\n",
      "Name: bldg_addr, Length: 4375, dtype: object,), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/geopy/geocoders/base.py\", line 355, in _call_geocoder\n",
      "    page = requester(req, timeout=timeout, **kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/urllib/request.py\", line 532, in open\n",
      "    response = meth(req, response)\n",
      "  File \"/anaconda3/lib/python3.6/urllib/request.py\", line 642, in http_response\n",
      "    'http', request, response, code, msg, hdrs)\n",
      "  File \"/anaconda3/lib/python3.6/urllib/request.py\", line 570, in error\n",
      "    return self._call_chain(*args)\n",
      "  File \"/anaconda3/lib/python3.6/urllib/request.py\", line 504, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/anaconda3/lib/python3.6/urllib/request.py\", line 650, in http_error_default\n",
      "    raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "urllib.error.HTTPError: HTTP Error 429: Too Many Requests\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/geopy/extra/rate_limiter.py\", line 126, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/geopy/geocoders/osm.py\", line 387, in geocode\n",
      "    self._call_geocoder(url, timeout=timeout), exactly_one\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/geopy/geocoders/base.py\", line 373, in _call_geocoder\n",
      "    raise ERROR_CODE_MAP[code](message)\n",
      "geopy.exc.GeocoderQuotaExceeded: HTTP Error 429: Too Many Requests\n",
      "RateLimiter swallowed an error after 2 retries. Called with (*(0           145 East 48th Street NYC\n",
      "1           350 West 42nd Street NYC\n",
      "2             211 Madison Avenue NYC\n",
      "3           350 West 57th Street NYC\n",
      "4           500 West 43rd Street NYC\n",
      "                    ...             \n",
      "4387        150 West 51st Street NYC\n",
      "4388        224 East 52nd Street NYC\n",
      "4389        240 East 47th Street NYC\n",
      "4390    845 United Nations Plaza NYC\n",
      "4391    845 United Nations Plaza NYC\n",
      "Name: bldg_addr, Length: 4375, dtype: object,), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/geopy/geocoders/base.py\", line 355, in _call_geocoder\n",
      "    page = requester(req, timeout=timeout, **kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/urllib/request.py\", line 532, in open\n",
      "    response = meth(req, response)\n",
      "  File \"/anaconda3/lib/python3.6/urllib/request.py\", line 642, in http_response\n",
      "    'http', request, response, code, msg, hdrs)\n",
      "  File \"/anaconda3/lib/python3.6/urllib/request.py\", line 570, in error\n",
      "    return self._call_chain(*args)\n",
      "  File \"/anaconda3/lib/python3.6/urllib/request.py\", line 504, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"/anaconda3/lib/python3.6/urllib/request.py\", line 650, in http_error_default\n",
      "    raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "urllib.error.HTTPError: HTTP Error 429: Too Many Requests\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/geopy/extra/rate_limiter.py\", line 126, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/geopy/geocoders/osm.py\", line 387, in geocode\n",
      "    self._call_geocoder(url, timeout=timeout), exactly_one\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/geopy/geocoders/base.py\", line 373, in _call_geocoder\n",
      "    raise ERROR_CODE_MAP[code](message)\n",
      "geopy.exc.GeocoderQuotaExceeded: HTTP Error 429: Too Many Requests\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(geocode(df_graph['bldg_addr'] + \" NYC\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "GeocoderQuotaExceeded",
     "evalue": "HTTP Error 429: Too Many Requests",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/geopy/geocoders/base.py\u001b[0m in \u001b[0;36m_call_geocoder\u001b[0;34m(self, url, timeout, raw, requester, deserializer, **kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequester\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    641\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 642\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 429: Too Many Requests",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mGeocoderQuotaExceeded\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-02aedc5c0f5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_graph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bldg_addr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mlocation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeolocator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeocode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" NYC\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/geopy/geocoders/osm.py\u001b[0m in \u001b[0;36mgeocode\u001b[0;34m(self, query, exactly_one, timeout, limit, addressdetails, language, geometry, extratags, country_codes, viewbox, bounded)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         return self._parse_json(\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_geocoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexactly_one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m         )\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/geopy/geocoders/base.py\u001b[0m in \u001b[0;36m_call_geocoder\u001b[0;34m(self, url, timeout, raw, requester, deserializer, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m                                 exc_info=False)\n\u001b[1;32m    372\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mERROR_CODE_MAP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mGeocoderServiceError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mGeocoderQuotaExceeded\u001b[0m: HTTP Error 429: Too Many Requests"
     ]
    }
   ],
   "source": [
    "addr_list = []\n",
    "lat_list = []\n",
    "long_list = []\n",
    "\n",
    "c = 0\n",
    "bad_c = 0\n",
    "\n",
    "for row, value in df_graph['bldg_addr'].items():\n",
    "    location = geolocator.geocode(value + \" NYC\")\n",
    "    \n",
    "    try:\n",
    "        lat_list.append(location.latitude)\n",
    "        long_list.append(location.longitude)\n",
    "        addr_list.append(value)\n",
    "        \n",
    "        c = c + 1\n",
    "        print(\"count: \", c)\n",
    "        print(value)\n",
    "    except:\n",
    "        bad_c = bad_c + 1\n",
    "        print(\"did not work: \", value)\n",
    "        print(\"bad count: \", bad_c)\n",
    "        continue\n",
    "    \n",
    "    time.sleep(2)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row, value in df_graph['bldg_addr'].items():\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addr_list = []\n",
    "lat_list = []\n",
    "long_list = []\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"specify_your_app_name_here\")\n",
    "\n",
    "for row, value in df_graph['bldg_addr'].items():\n",
    "    try:\n",
    "        location = geolocator.geocode(value + \" NYC\")\n",
    "        lat_list.append(location.latitutde)\n",
    "        long_list.append(location.longitude)\n",
    "        addr_list.append(value)\n",
    "        print(\"good: \", value)\n",
    "    except:\n",
    "        lat_list.append(np.nan)\n",
    "        long_list.append(np.nan)\n",
    "        addr_list.append(value)\n",
    "        print(\"not good: \", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the library\n",
    "import folium\n",
    "import pandas as pd\n",
    " \n",
    "# Make a data frame with dots to show on the map\n",
    "data = pd.DataFrame({\n",
    "   'lat':[-58, 2, 145, 30.32, -4.03, -73.57, 36.82, -38.5],\n",
    "   'lon':[-34, 49, -38, 59.93, 5.33, 45.52, -1.29, -12.97],\n",
    "   'name':['Buenos Aires', 'Paris', 'melbourne', 'St Petersbourg', 'Abidjan', 'Montreal', 'Nairobi', 'Salvador'],\n",
    "   'value':[10,12,40,70,23,43,100,43]\n",
    "})\n",
    "data\n",
    " \n",
    "# Make an empty map\n",
    "m = folium.Map(location=[20,0], tiles=\"Mapbox Bright\", zoom_start=2)\n",
    " \n",
    "# I can add marker one by one on the map\n",
    "for i in range(0,len(data)):\n",
    "   folium.Circle(\n",
    "      location=[data.iloc[i]['lon'], data.iloc[i]['lat']],\n",
    "      popup=data.iloc[i]['name'],\n",
    "      radius=data.iloc[i]['value']*10,\n",
    "      color='crimson',\n",
    "      fill=True,\n",
    "      fill_color='crimson'\n",
    "   ).add_to(m)\n",
    " \n",
    "# Save it as html\n",
    "m.save('mymap.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(location.raw)\n",
    "{'place_id': '9167009604', 'type': 'attraction', ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overarching graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_drop[df_drop['sold_price'] < 8000000]\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(df_final['sold_season'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Investigating Days on Market -- won't include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_drop[['full_name', 'sold_date_dt', 'listed', 'days_on_market', 'days_on_market_1', 'url']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_drop[df_drop['days_on_market_1'] < df_drop['days_on_market']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_drop[df_drop['days_on_market_1'] > 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_drop[['full_name', 'sold_date_dt', 'listed', 'days_on_market', 'url']].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['sold_price']\n",
    "bldg = ['full_name'] #'bldg_name', 'bldg_addr']\n",
    "cont = ['bldg_rating', \n",
    "        'apt_floor',\n",
    "        'square_feet', \n",
    "        'beds', \n",
    "        'baths', \n",
    "        'monthly_common_charges', \n",
    "        'monthly_real_estate_taxes']\n",
    "cat = ['sold_season', 'neighborhood', 'year']\n",
    "model_columns = bldg + cont + cat + target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_df = df_drop.loc[:, model_columns]\n",
    "#smaller_df.shape\n",
    "smaller_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NAs\n",
    "smaller_df = smaller_df.dropna().reset_index(drop = True)\n",
    "# smaller_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(smaller_df, diag_kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers. 21 outliers greater than 8 Million\n",
    "smaller_df_no_out = smaller_df[smaller_df['sold_price'] < 6000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(smaller_df['sold_price'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_df_no_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Dummies\n",
    "df_model = pd.get_dummies(smaller_df_no_out.drop('full_name', axis = 1), columns = ['sold_season', 'neighborhood'])\n",
    "\n",
    "# Remove large outliers from sold\n",
    "\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X values and y values\n",
    "X = df_model.drop('sold_price', axis = 1)\n",
    "y = df_model['sold_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weird = 10, 14\n",
    "# normal = 11, 12, 13\n",
    "rs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hold out 20% of the data for final testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state= rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Looking at different random states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(X['apt_floor'][X['apt_floor'] < 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(smaller_df_no_out['apt_floor'][smaller_df_no_out['apt_floor'] < 100], smaller_df_no_out['sold_price'][smaller_df_no_out['apt_floor'] < 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rs_10 = 10 #weird\n",
    "rs_14 = 14 #weird\n",
    "rs_11 = 11 #normal\n",
    "X_train10, X_test10, y_train10, y_test10 = train_test_split(X, y, test_size=.2, random_state= rs_10)\n",
    "X_train14, X_test14, y_train14, y_test14 = train_test_split(X, y, test_size=.2, random_state= rs_14)\n",
    "X_train11, X_test11, y_train11, y_test11 = train_test_split(X, y, test_size=.2, random_state= rs_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "smaller_df_no_out.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 14 is weird\n",
    "smaller_df_no_out.loc[list(X_train14.index), :]['baths'].value_counts()\n",
    "#smaller_df_no_out.loc[list(X_train14.index), :]['monthly_common_charges'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "smaller_df_no_out['neighborhood'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "smaller_df_no_out['sold_season'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "smaller_df_no_out['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "smaller_df_no_out.loc[list(X_test14.index), :]['baths'].value_counts()\n",
    "#smaller_df_no_out.loc[list(X_test14.index), :]['monthly_common_charges'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#smaller_df_no_out.loc[list(X_test14.index), :]['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#smaller_df_no_out.loc[list(X_train14.index), :]['sold_season'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "smaller_df_no_out.loc[list(X_train11.index), :]['beds'].value_counts()\n",
    "#smaller_df_no_out.loc[list(X_train11.index), :]['monthly_common_charges'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "smaller_df_no_out.loc[list(X_test11.index), :]['beds'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Simple Model - 1 Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#sns.distplot(df_model['sold_price'][df_model['sold_price'] <10000000])\n",
    "#plt.scatter(df_model['sold_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "column_1 = ['square_feet','monthly_common_charges', 'monthly_real_estate_taxes', 'beds', 'baths', 'apt_floor'] # 'beds', 'baths', \n",
    "one_col_model = LinearRegression()\n",
    "one_col_model.fit(X_train.loc[:, column_1], y_train)\n",
    "one_col_model.score(X_train.loc[:, column_1], y_train)\n",
    "#one_col_model.coef_, one_col_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "one_col_model.score(X_test.loc[:, column_1],y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cross_val_score(X_train.loc[:, column_1], y_train, cv = 5, scoring = 'r2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Comparing Simple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Models\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm_reg = Ridge(alpha = 10)\n",
    "\n",
    "kf = KFold(n_splits=20, shuffle=True, random_state = 1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "np.mean(cross_val_score(lm, X_train, y_train, # estimator, features, target\n",
    "                cv=kf, # number of folds \n",
    "                scoring='r2')) # scoring metric\n",
    "print(cross_val_score(lm, X_train, y_train, # estimator, features, target\n",
    "                cv=kf, # number of folds \n",
    "                scoring='r2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Ridge Regression\n",
    "np.mean(cross_val_score(lm_reg, X_train, y_train, # estimator, features, target\n",
    "                cv=kf, # number of folds \n",
    "                scoring='r2')) # scoring metric\n",
    "print(cross_val_score(lm_reg, X_train, y_train, # estimator, features, target\n",
    "                cv=kf, # number of folds \n",
    "                scoring='r2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Linear Regression. Compare Train and Test\n",
    "lm.fit(X_train, y_train)\n",
    "print(\"Train Score: \", lm.score(X_train, y_train))\n",
    "print(\"Test Score: \", lm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Ridge Regression. Compare Train and Test\n",
    "lm_reg.fit(X_train, y_train)\n",
    "print(\"Train Score: \", lm_reg.score(X_train, y_train))\n",
    "print(\"Test Score: \", lm_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression with Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale Training data and Transform testing data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Cross Validation on Ridge Regression with scaled features. It is similar to simple models\n",
    "np.mean(cross_val_score(lm_reg, X_train_scaled, y_train, cv=kf, scoring = 'r2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression\n",
    "lm_reg = Ridge(alpha=1)\n",
    "lm_reg.fit(X_train_scaled, y_train)\n",
    "print(lm_reg.score(X_train_scaled, y_train))\n",
    "print(lm_reg.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn import linear_model\n",
    "#lasso_model = LassoCV()\n",
    "lasso_model_2 = linear_model.Lasso(alpha = 100)\n",
    "#lasso_model_3 = linear_model.Lasso(alpha = 1000)\n",
    "lasso_model_2.fit(X_train_scaled, y_train)\n",
    "print(\"Trained Score: \", lasso_model_2.score(X_train_scaled, y_train))\n",
    "print(\"Test Score: \", lasso_model_2.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model_2.fit(X_train_scaled,y_train)\n",
    "pred = lasso_model_2.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot residuals\n",
    "res = y_test - pred\n",
    "plt.scatter(pred, res)\n",
    "plt.title(\"Residual plot\")\n",
    "plt.xlabel(\"prediction\")\n",
    "plt.ylabel(\"residuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cross_val_score(lasso_model_2, X_train_scaled, y_train, cv=kf, scoring = 'r2'))\n",
    "# score is 0.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_poly = PolynomialFeatures(degree=2) \n",
    "lm_poly.fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Feature Interactions / Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2) \n",
    "\n",
    "# Poly Transform adds new values to the tran, test, and validation sets\n",
    "#X_train_poly = poly.fit_transform(X_train.values) # fits and transforms the data in one spot\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "# scale is part of the model. So, need to fit to the training data. And test this fit on the \n",
    "# test data.\n",
    "\n",
    "#X_test_poly = poly.transform(X_test.values)\n",
    "X_test_poly = poly.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# So we know what the columns are for polynomial-ized variables\n",
    "poly_train_df = pd.DataFrame(poly.fit_transform(X_train), columns = poly.get_feature_names(input_features = X_train.columns))\n",
    "poly_col = poly_train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Poly_train_df = pd.DataFrame(poly.fit_transform(X_train), columns = poly.get_feature_names(input_features = X_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Values show that we need to scale. Model is over fit\n",
    "lm_poly = LinearRegression()\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state = 71)\n",
    "print(\"Mean value fom cv: \", np.mean(cross_val_score(lm_poly, X_train_poly, y_train, cv=kf, scoring='r2')))\n",
    "cross_val_score(lm_poly, X_train_poly, y_train, cv=kf, scoring='r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Run linear Regression\n",
    "lm_poly = LinearRegression()\n",
    "\n",
    "lm_poly.fit(X_train_poly, y_train)\n",
    "print(\"Train Score: \", lm_poly.score(X_train_poly, y_train))\n",
    "print(\"Test Score: \", lm_poly.score(X_test_poly, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Standardize Features, and run Regularization Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Fit standard scalar to the X train values to get mean and std. dev.\n",
    "std = StandardScaler()\n",
    "std.fit(X_train_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Applies scalar to training set. Subtracts mean and divides by st. dev. for every value\n",
    "X_tr = std.transform(X_train_poly)\n",
    "X_te = std.transform(X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lasso_model = LassoCV()\n",
    "lasso_model.fit(X_tr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lasso_model.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.mean(cross_val_score(lasso_model, X_tr, y_train, # estimator, features, target\n",
    "                cv=kf, # number of folds \n",
    "                scoring='r2')) # scoring metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lasso_model.score(X_tr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lasso_model.score(X_te, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feature_list = list(zip(poly_col, lasso_model.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sorted(feature_list, key=lambda tup: tup[1])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sorted(feature_list, key=lambda tup: tup[1], reverse = True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "std.fit(X_train_poly)\n",
    "\n",
    "X_tr = std.transform(X_train_poly)\n",
    "X_te = std.transform(X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.mean(cross_val_score(lm_reg, X_tr, y_train, cv = kf, scoring = 'r2'))\n",
    "#cross_val_score(lm_reg, X_tr, y_train, cv = kf, scoring = 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lm_reg = Ridge(alpha=1)\n",
    "lm_reg.fit(X_tr, y_train)\n",
    "print(lm_reg.score(X_tr, y_train))\n",
    "print(lm_reg.score(X_te, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feature_list = list(zip(poly_col, lm_reg.coef_))\n",
    "sorted(feature_list, key=lambda tup: tup[1])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sorted(feature_list, key=lambda tup: tup[1], reverse = True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_model.drop('sold_price', axis = 1)\n",
    "y = df_model['sold_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "rgr = LinearRegression()\n",
    "rgr.fit(X,y)\n",
    "pred = rgr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_reg = Ridge(alpha=1)\n",
    "lm_reg.fit(X_tr, y_train)\n",
    "pred = lm_reg.predict(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot residuals\n",
    "res = y_test - pred\n",
    "plt.scatter(pred, res)\n",
    "plt.title(\"Residual plot\")\n",
    "plt.xlabel(\"prediction\")\n",
    "plt.ylabel(\"residuals\")\n",
    "\n",
    "# res is NEGATIVE when prediction is LARGER than actual (over predicting)\n",
    "# res is POSITIVE when prediction is SMALLER than actual (under predicting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "# Plot Q-Q plot\n",
    "#plt.subplot(1, 3, 3)\n",
    "#Generates a probability plot of sample data against the quantiles of a \n",
    "# specified theoretical distribution \n",
    "stats.probplot(res, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Normal Q-Q plot\")\n",
    "\n",
    "# Has problems predicting really large and reall small values\n",
    "# Comparing the residuals to a normal distribution\n",
    "# This is HEAVY TAILED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_reg = Ridge(alpha=1)\n",
    "lm_reg.fit(X_tr, y_train)\n",
    "pred = lm_reg.predict(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot your predicted values on the x-axis, and your residuals on the y-axis\n",
    "data = pd.DataFrame()\n",
    "data['predict']= lm_reg.predict(X_te)\n",
    "data['resid']= y_test - data['predict']\n",
    "with sns.axes_style('white'):\n",
    "    plot=data.plot(kind='scatter',\n",
    "                  x='predict',y='resid',alpha=0.2,figsize=(10,6))\n",
    "\n",
    "# Heteroskedasticity is shown here. Residuals look like a \"tornado\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Higher prediction, the more negative the residuals, meaning \n",
    "# the model is over predicting.\n",
    "\n",
    "# Lower prediction, the more positive the residuals, meaning\n",
    "# the model is under predicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect histogram\n",
    "#y_test[y_test < 10000000].hist(bins=25)\n",
    "#plt.dist('Histogram of Dependent Variable (User Counts)');\n",
    "\n",
    "#y_test[y_test < 10000000].hist(bins=25)\n",
    "plt.dist(y_test[y_test < 10000000]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y[y < 10000000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagnose/inspect residual normality using qqplot:\n",
    "stats.probplot(data['resid'], dist=\"norm\", plot=plt)\n",
    "plt.title(\"Normal Q-Q plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Investigating Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(df_clean['sold_date_dt'], df_clean['sold_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(df_clean['sold_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(df_clean) - len([df_clean['sold_price'] < 8000000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(df_model['sold_price'][df_model['sold_price'] < 10000000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
